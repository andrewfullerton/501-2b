---
title: "Assignment 2b"
format: gfm
editor: source
---

```{r}
# Set global chunk options for error handling
knitr::opts_chunk$set(error = TRUE)
```

## Preparing environment and data

```{r}
library(tidyverse)
library(broom)
library(geepack)
library(nlme)
```

```{r}
cd4 <- read_csv("data/cd4data.csv")

cd4 <- cd4 |>
  mutate(
    Treatment = as.factor(Treatment),
    Gender = as.factor(Gender)
  )

glimpse(cd4)
```

## 1) Explore the data using ggplot

Before beginning EDA, we should recount what is already known about the data from the Henry et al. (1998) paper and data collection methods:

-   Data are collected from a randomized, double-blind study of advanced AIDS patients.

-   Patients were randomized to 1 of 4 daily regimens with regimens corresponding to different combinations of therapies.

-   CD4 measurements were scheduled for collection at baseline and then every 8 weeks: but the CD4 count data are **unbalanced** due to mistimed measurements, missed visits, and dropout from the trial; this is something we should look into further during EDA to understand if the missingness may be biasing the results in any way.

To begin, we should look for high-level differences across the treatment groups. (NOTE: all analysis going forward from here is based on the assumption that we are investigating the effect of treatment on CD4 count)

```{r}
theme_set(theme_minimal())

ggplot(cd4,  aes(x = Treatment, y = LogCD4)) +
  geom_boxplot(aes(fill = Treatment)) +
  labs(title = "Log CD4 count by treatment group")
```

This plot does not suggest that are any glaring difference between the treatment groups in terms of aggregate CD4 count (although there is a general trend of CD4 count increasing across each treatment group). This is, however, an oversimplified visualization and we should look at how the treatment differ **over time** to get a better sense of how treatment may effect CD4 count.

```{r}
ggplot(cd4, aes(x = Week, y = LogCD4)) +
  stat_summary(geom = "line", fun = mean) +
  stat_summary(geom = "point", fun = mean) +
  geom_smooth(method = "loess", aes(color = Treatment)) +
  facet_wrap(~Treatment) +
  labs(title = "Average Log CD4 count over time by treatment",
       x = "Weeks", y = "Log CD4")
```

This plot suggests that are some patterned differences between treatment groups, but that the general trend of CD4 count decreasing over time appears to be roughly the same regardless of treatment assignment. It is noteworthy that in treatment 3 (zidovudine plus 400mg of didanosine) and treatment 4 (zidovudine plus 400mg of didanosine plus 400mg of nevirapine) there seems to be a slightly more pronounced increase in average CD4 counts in the initial weeks of treatment compared to treatment 1 (zidovudine alternating monthly) and treatment 2 (zidovudine plus 2.25mg of zalcitabine).

These are, however, still just aggregate trends. They do not adequately represent the change in CD4 within-individuals in the different treatment groups. This next plot explicitly shows the individual trajectories underlying the fitted LOESS line.

```{r}
ggplot(cd4, aes(x = Week, y = LogCD4, group = ID)) +
  geom_line(alpha = 0.3) +
  geom_smooth(aes(group = Treatment, color = Treatment), method = "loess", se = FALSE, 
              linewidth = 1.2) +
  facet_wrap(~Treatment) +
  labs(title = "Individual CD4 counts over time by treatment",
       x = "Weeks", y = "Log CD4")
```

With this plot of the individual trajectories, we can see that there are far more observations in the earlier weeks (i.e. dense clusters of black lines/individual trajectories). In later weeks, the lines get increasingly sparse due to loss to follow-up, dropouts, etc. There does not appear to be any notable differences in losses to follow-up based on this plot alone, but it is difficult to tell. It may be the case that some of these differences are due to the lack of balance in the data owing to dropout and/or missing measurements.

```{r}
cd4 |>
  group_by(Treatment, ID) |>
  summarise(obs_count = n(), .groups = "drop") |>
  ggplot(aes(x = Treatment, y = obs_count, fill = Treatment)) +
  geom_boxplot() +
  geom_jitter(alpha = 0.3) +
  labs(title = "Observations per unit",
       x = "Treatment group", y = "Number of observations")
```

This plot suggest that there are not any patterned differences in the number of observations per unit (i.e. number of follow-up measures per person). To be sure that there are not other patterned differences responsible for the observed differences between treatment groups, however, we should nonetheless verify that measured covariates are roughly balanced across treatment groups (NOTE: the Henry et al. (1998) paper tells us that they are balanced, but for the sake of thoroughness, I will verify this claim).

```{r}
age <- ggplot(cd4, aes(x = Treatment, y = Age, fill = Treatment)) +
  geom_boxplot() +
  labs(title = "Age",
       x = "Treatment",
       y = "Age") +
  theme(legend.position = "none")

gender <- cd4 |>
  group_by(Treatment, Gender) |>
  summarise(count = n(), .groups = "drop") |> 
  ggplot(aes(x = Treatment, y = count, fill = Gender)) +
  geom_col(position = "stack") +
  labs(title = "Gender",
       x = "Treatment", 
       y = "Count")

baseline <- cd4 |> 
  filter(Week == 0) |>
  ggplot(aes(x = Treatment, y = LogCD4)) +
  geom_boxplot(aes(fill = Treatment)) +
  labs(title = "Baseline CD4",
       x = "Treatment",
       y = "Baseline Log CD4") +
  theme(legend.position = "none")

observations <- cd4 |>
  group_by(Treatment, ID) |>
  summarise(obs_count = n(), .groups = "drop") |>
  ggplot(aes(x = Treatment, y = obs_count, fill = Treatment)) +
  geom_boxplot() +
  labs(title = "Observations per unit",
       x = "Treatment", y = "Number of observations") +
  theme(legend.position = "none")

gridExtra::grid.arrange(age, gender, baseline, observations, ncol = 2,
                        top = "Covariates and possible sources of bias by treatment group")
```

This plot verifies that the covariates (including baseline CD4 and observations per unit) are approximately balanced between the 4 treatment groups. We should also verify the relationship of the covariates with the outcome:

```{r}
age_outcome <- cd4 |> 
  ggplot(aes(x = Age, y = LogCD4)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "loess", se = FALSE, color = "red") +
  labs(x = "Age", y = "LogCD4")

gender_outcome <- cd4 |> 
  ggplot(aes(x = Gender, y = LogCD4)) +
  geom_boxplot(alpha = 0.6) +
  labs(x = "Gender", y = "LogCD4")

gridExtra::grid.arrange(age_outcome, gender_outcome, ncol = 2,
                        top = "Covariates vs. Log CD4 count")
```

Now that we have a general sense of the relationship between treatment group and CD4 count over time and have verified the balance of covariates and other biasing factors across treatment groups, we can model.

## 2) Model the data using a linear model with correlated error terms

Given the small number of covariates, backwards selection will be used to identify the adjustment set. Covariates that are not statistically significant will be removed and if model fit (AIC/BIC) improves then the covariate will be omitted from the final model. NOTE: to avoid redundancy, covariate selection will be undertaken using the first proposed model and the same covariates will be used to examine all subsequent correlation structures.

```{r}
glimpse(cd4)

gls(LogCD4 ~ Treatment + Week + Age + Gender,
    data = cd4,
    correlation = corCompSymm(form = ~1 | ID)) |> summary()
```

Our full model has AIC of 12281.35 and BIC of 12340.05; only one included covariate is not statistically significant (gender).

```{r}
gls(LogCD4 ~ Treatment + Week + Age,
    data = cd4,
    correlation = corCompSymm(form = ~1 | ID)) |> summary()
```

With gender omitted from the model, there is a slight improvement in model fit (AIC = 12277.89, BIC = 12330.07) and all remaining covariates are statistically significant. We can also rest assured knowing that the study used has a randomized design and, as evident in EDA, gender is roughly balanced across treatment groups. Gender will be omitted from the model going forward.

## GLS

### GLS (compound symmetry)

```{r}
gls(LogCD4 ~ Treatment + Week + Age, 
    data = cd4, 
    correlation = corCompSymm(form = ~1 | ID)) |> summary()
```

Using a compound symmetry correlation structure implies that: i) the variance of each repeated measure is constant, and ii) the correlation between any two repeated measurements, regardless of their temporal or ordinal distance, is the same. This means that within-individual measures that are closer together in time are not assumed to be more or less correlated than those further apart.

From a conceptual standpoint, this structure does not seem to align well with our data. We would expect that measurements taken closer together in time should be more strongly correlated with each other. By not accounting for this in our correlation structure, we are likely underestimating our standard errors, which may lead to overestimating the effects of the treatment protocols.

### GLS (AR1)

```{r}
gls(LogCD4 ~ Treatment + Week + Age,
    data = cd4,
    correlation = corAR1(form = ~1 | ID)) |> summary()
```

In contrast to compound symmetry, AR(1) explicitly incorporates the idea that measurements taken closer together in time should be more strongly correlated than those further apart. This feature of AR(1) makes it potentially more suitable for our data than compound symmetry. However, it is important to note that AR(1) assumes measurements are taken at equal and consistent intervals. This assumption is violated in our data due to missing measurements and losses to follow-up, which could lead to an overestimation of the correlation between some measurements, potentially resulting in artificially low standard errors.

### GLS (unstructured)

```{r}
gls(LogCD4 ~ Treatment + Week + Age,
    data = cd4,
    correlation = corSymm(form = ~1 | ID)) |> summary()
```

An unstructured correlation structure is the most flexible compared to compound symmetry and AR(1). Instead of imposing specific assumptions about the correlation between measurements, this structure freely estimates every pairwise correlation between repeated measurements. As such, it is driven by the data itself, unlike compound symmetry and AR(1), which are fitted to the data with predefined assumptions.

Here, we are running into a convergence issue. Because we are estimating correlations for each pair of time points within each individual, the computational complexity associated with this may be causing non-convergence. The non-convergence may also be a result of the unbalanced data: because some individuals have more repeated measurements than others, the unstructured correlation model may, in effect, be drastically overfitting/underfitting the model to certain individuals.

## GEE GLM

Compared to a GLS approach, using a GEE GLM to account for correlated data is a more 'robust' approach in that it is less sensitive to correlation structure misspecification. A GLS approach assumes that we are specifying the true correlation structure and thus directly models the correlation structure whereas a GEE GLM approach only assumes that we specify a working (and somewhat arbitrary) correlation structure.

### GEE GLM (compound symmetry)

```{r}
geeglm(LogCD4 ~ Treatment + Week + Age,
       data = cd4,
       id = ID,
       family = gaussian,
       corstr = "exchangeable") |> tidy()
```

### GEE GLM (AR1)

```{r}
geeglm(LogCD4 ~ Treatment + Week + Age,
       data = cd4,
       id = ID,
       family = gaussian,
       corstr = "ar1") |> tidy()
```

### GEE GLM (unstructured)

```{r}
geeglm(LogCD4 ~ Treatment + Week + Age,
       data = cd4,
       id = ID,
       family = gaussian,
       corstr = "unstructured") |> tidy()
```

```{r}
models_all <- list(
  "Compound Symmetry (GLS)" = gls(LogCD4 ~ Treatment + Week + Age, 
                                  data = cd4, 
                                  correlation = corCompSymm(form = ~1 | ID)),
  "Compound Symmetry (GEE GLM)" = geeglm(LogCD4 ~ Treatment + Week + Age, data = cd4, id = ID,
                                         family = gaussian, corstr = "exchangeable"),
  "AR1 (GLS)" = gls(LogCD4 ~ Treatment + Week + Age,
                    data = cd4,
                    correlation = corAR1(form = ~1 | ID)),
  "AR1 (GEE GLM)" = geeglm(LogCD4 ~ Treatment + Week + Age, data = cd4, id = ID, 
                           family = gaussian, corstr = "ar1"),
  "Unstructured (GEE GLM)" = geeglm(LogCD4 ~ Treatment + Week + Age, data = cd4, id = ID, 
                          family = gaussian, corstr = "unstructured")
)

modelsummary::modelsummary(models_all, 
                           digits = 3,
                           estimate = "{estimate} ({std.error})",
                           statistic = "p = {p.value}")
```

With both GLS and GEE GLM approaches, we observe differences in standard errors and point estimates when using different correlation structures. While there were some differences in the specific point estimates and standard errors produced, the overall trends and conclusions were similar between the models.

A key difference between the models lies in overall model fit. The GLS models consistently outperformed the GEE GLM models in terms of AIC, BIC, and R². This is expected: GLS estimation is optimized for efficiency and uses a full-likelihood estimation method, directly modeling the correlation structure, whereas GEE is optimized for robustness and employs a quasi-likelihood estimation method. The trade-off is that when the correlation structure is specified correctly, GLS produces more efficient estimates but is sensitive to misspecification. On the other hand, GEE provides consistent estimates even when the correlation structure is misspecified.

Despite these methodological differences, the main findings and conclusions remain unchanged: Only treatment 4 (zidovudine plus 400mg of didanosine and 400mg of nevirapine) is significantly better than treatment 1 (zidovudine alternating monthly), while the other treatments do not show significant differences in efficacy.

## 3) Discuss the research questions you are able to explore using a linear model with correlated error terms

1.  How effective are different therapies?

Linear models with correlated error terms are well-suited for modeling the efficacy of different therapies. By incorporating correlated error terms (via GEE or GLS), these models provide more accurate and valid standard error estimates by accounting for within-subject correlation due to repeated measurements. In contrast, a standard linear model without correlated error terms assumes no correlation between measurements from the same subject, which can lead to artificially low standard errors and narrow confidence intervals.

2.  How do the effectiveness of therapies differ according to patient characteristics (treatment effect heterogeneity)?

Linear models with correlated error terms are suitable for comparing therapies wherein the effects of therapies may differ according to certain patient characteristics. While not the focus of this analysis, linear models with correlated error terms (like all linear models) allow for exploration of effect modification via the inclusion of interaction terms. It may, for instance, be the case that some treatments are particularly effective for younger patients while others are particularly effective for older patients.

3.  How are observations correlated with one another?

A key aspect of linear models with correlated error terms is that the specification of the correlation structure itself is often of scientific interest. As discussed in Question 2, different correlation structures make different assumptions about how observations are correlated, and choosing the appropriate structure can provide valuable insights into the nature of the data.

### Limitations to linear models with correlated error terms

There are also important limitations to note when using linear models with correlated error terms. Linear models with correlated error terms do not explicitly model variability the same way that mixed-effects models do. We may, for example, want to know whether certain therapies are more effective for certain patients. A linear model with correlated error terms limits us to average estimations: while we can estimate how effective a treatment is depending on certain characteristics after accounting for within-individual correlations, we cannot estimate unobserved individual-specific deviations from those averages. A mixed-effects model, by contrast, allows us to estimate a random slope for each individual thereby estimating how effective treatment is for a particular individual. Put simply: mixed-effects models allow us to build a model for each individual whereas linear models with correlated error terms limit us to a single model that account for within-individual correlations.
